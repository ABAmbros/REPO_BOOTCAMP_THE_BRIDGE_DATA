{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios de razonar\n",
    "Para estos ejercicios no hace falta escribir ni una línea de código. Simmplemente hay que responder a las preguntas.\n",
    "\n",
    "### Pregunta 1\n",
    "**Si entrenas 5 modelos diferentes y obtienes en los 5 un 95% de acierto, ¿sería posible combinar los 5 modelos para mejorar ese porcentaje?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREO QUE ES POSIBLE COMBINARLOS, MEDIANTE ENSEMBLE, EL PORCENTAJE SI MEJORA, PODEMOS LLEGAR AL 100%, CUANDO LAS VOTACIONES CAMBIAN A UN MODELO QUE AL COMBINARLOS NO SE REPITA EN NINGUNO DE ELLOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2\n",
    "**¿Cuál es la diferencia entre un hard y un soft voting classifier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUES SOFT VOTING HACE UNA COMBINACIÓN DE LA PROBABILIDAD DE CADA UNA DE LAS PREDICCIONES DE CADA MODELO UTILIZADO, calculamos la media,  Y AHÍ ELIGE LA MÁS ALTA DE ELLAS. Y HARD VOTING SE HACE CON EL RESULTADO QUE HAYA OBTENIDO MAYOR NÚMERO DE VOTOS EN SU TOTAL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3\n",
    "**Para mejorar los tiempos de entrenamiento, se suelen paralelizar los procesos de ejecución en el ordenador (un proceso por core) para que entrene más rápido. ¿Sería posible paralelizar el entrenamiento de los algoritmos de bagging vistos en clase? ¿Y los de boosting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EL BAGGING se puede entrenar en paralelo, por su cuenta cada modelo, y si se pueden paralelizar, y cada uno da su opinión, y se va agregando, CREO ENTONCES QUE SI SE PODRÍA CON ESTE MÉTODO DE ENTRENAMIENTO. EL BOOSTING TIRA MAS POR IR AJUSTANDO SEGÚN EL PESO AL OBSERVAR LOS DATOS DE MANERA SECUENCIAL, con este no. Este tenemos que esperar a que termine de trabajar uno para que empiece otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 4\n",
    "**¿Qué podríamos modificar en nuestro algoritmo de AdaBoost para mejorarlo en el caso de que se produzca underfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUMENTAR EL LIMITE DE ESTIMADORES, Y LA RAPIDEZ DEL ENTRENAMIENTO. learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5\n",
    "**¿Qué podemos hacer si tenemos overfitting en GradientBoosting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOCAR LOS PARÁMETROS TANTO DE N_ESTIMATOR como EL DE LA PROFUNDIDAD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
